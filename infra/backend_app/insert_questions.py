"""
Question Database Insertion Module
===================================

This module reads parsed JSON question data and inserts it into the MySQL
quizbank database, including support for page image paths and page numbers
(supports multi-page questions).

Features:
- Inserts questions with all metadata (difficulty, tags, options, answers)
- Handles multiple page image paths and page numbers per question
- Maintains version control for questions
- Links questions to source files
- Provides detailed insertion logging

The module expects JSON files generated by llm_parser.py.
"""

import os
import json
import mysql.connector
from datetime import datetime
import time


# === 1. DB connection settings ===
DB_CONFIG = {
    "host": os.getenv("MYSQL_HOST", "db"),
    "user": os.getenv("MYSQL_USER", "root"),
    "password": os.getenv("MYSQL_PASSWORD", "root"),
    "database": os.getenv("MYSQL_DATABASE", "quizbank"),
    "port": int(os.getenv("MYSQL_PORT", 3306)),
}

# === 2. Paths ===
JSON_DIR = os.path.join("data", "json_output")


def connect_to_database(max_retries=5, retry_delay=3):
    """
    Establish connection to MySQL database with retry logic.
    
    Attempts to connect to the database multiple times with delays between
    attempts to handle cases where the database is still initializing.
    
    Parameters
    ----------
    max_retries : int, default=5
        Maximum number of connection attempts.
    retry_delay : int, default=3
        Seconds to wait between retry attempts.
        
    Returns
    -------
    tuple of (connection, cursor)
        MySQL connection and cursor objects if successful.
        
    Raises
    ------
    mysql.connector.Error
        If connection fails after all retry attempts.
    """
    for attempt in range(max_retries):
        try:
            print(f" Attempting to connect to database (attempt {attempt + 1}/{max_retries})...")
            conn = mysql.connector.connect(**DB_CONFIG)
            cursor = conn.cursor()
            print(" Successfully connected to database!")
            return conn, cursor
        except mysql.connector.Error as e:
            if attempt < max_retries - 1:
                print(f" Connection failed: {e}")
                print(f" Retrying in {retry_delay} seconds...")
                time.sleep(retry_delay)
            else:
                print(f" Failed to connect after {max_retries} attempts")
                raise


def get_file_id(cursor, file_name):
    """
    Retrieve the database ID for a given file name.
    
    Parameters
    ----------
    cursor : mysql.connector.cursor
        Database cursor for executing queries.
    file_name : str
        Name of the PDF file (e.g., "exam_2024.pdf").
        
    Returns
    -------
    int
        The database ID of the file.
        
    Raises
    ------
    ValueError
        If no matching file record is found in the database.
    """
    cursor.execute("SELECT id FROM files WHERE file_name = %s", (file_name,))
    result = cursor.fetchone()
    if result:
        return result[0]
    else:
        raise ValueError(f" No matching file record for {file_name}")


def insert_question(cursor, q, file_id):
    """
    Insert a single question into the database.
    
    Handles all question fields including options, answers, page image paths
    (multiple), page numbers (multiple), and metadata. Sets question_base_id 
    equal to the new question's id for initial imports (no versions yet).
    
    Parameters
    ----------
    cursor : mysql.connector.cursor
        Database cursor for executing queries.
    q : dict
        Question dictionary parsed from JSON with all required fields.
    file_id : int
        Database ID of the source file this question came from.
        
    Returns
    -------
    int
        The database ID of the newly inserted question.
        
    Notes
    -----
    The function also updates question_base_id to match the question id
    since this is the first version of the question.
    """
    insert_query = """
        INSERT INTO questions (
            question_base_id, version_id, file_id,
            question_no, page_numbers, question_type, 
            difficulty_rating_manual, difficulty_rating_model,
            question_stem, question_stem_html,
            question_options, question_answer,
            page_image_paths, concept_tags,
            last_used, created_at, updated_at
        )
        VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
    """
    
    # Ensure arrays are properly formatted
    page_numbers = q.get("page_numbers", [])
    page_image_paths = q.get("page_image_paths", [])
    
    # Convert to lists if not already
    if not isinstance(page_numbers, list):
        page_numbers = [page_numbers] if page_numbers else []
    if not isinstance(page_image_paths, list):
        page_image_paths = [page_image_paths] if page_image_paths else []
    
    # For initial import, question_base_id = id (will be set after insert)
    data = (
        0,  # Temporary, will update after insert
        q.get("version_id", 1),
        file_id,
        q.get("question_no"),
        json.dumps(page_numbers),
        q.get("question_type"),
        q.get("difficulty_rating_manual"),
        q.get("difficulty_rating_model"),
        q.get("question_stem"),
        q.get("question_stem_html"),
        json.dumps(q.get("question_options", [])),
        q.get("question_answer"),
        json.dumps(page_image_paths),
        json.dumps(q.get("concept_tags", [])),
        q.get("last_used"),
        datetime.now(),
        datetime.now(),
    )
    
    cursor.execute(insert_query, data)
    question_id = cursor.lastrowid
    
    # Set question_base_id = id for initial imports (no versions yet)
    cursor.execute(
        "UPDATE questions SET question_base_id = %s WHERE id = %s", 
        (question_id, question_id)
    )
    
    return question_id


def process_json_files():
    """
    Main processing function to insert all questions from JSON files.
    
    Reads all JSON files in JSON_DIR, validates their content, and inserts
    questions into the database. Provides detailed logging of the insertion
    process including statistics on options, answers, page images (multiple),
    and page numbers (multiple).
    
    Returns
    -------
    None
        Results are printed to console and data is written to database.
        
    Notes
    -----
    - Skips empty or invalid JSON files with warnings
    - Rolls back transaction if any error occurs for a file
    - Commits successfully processed files individually
    - Supports multi-page questions with multiple images
    """
    
    # === NEW BLOCK: Check for pipeline-provided FILE_ID ===
    target_file_id_env = os.getenv("FILE_ID")
    pipeline_mode_file_id = None

    if target_file_id_env and target_file_id_env.isdigit():
        pipeline_mode_file_id = int(target_file_id_env)
        print(f" Detected pipeline mode. Prioritizing FILE_ID from environment: {pipeline_mode_file_id}")
    # =======================================================
    
    # Connect to database
    conn, cursor = connect_to_database()
    
    # Get list of JSON files
    json_files = [f for f in os.listdir(JSON_DIR) if f.lower().endswith(".json")]

    if not json_files:
        print(" No JSON files found in json_output directory")
        print(" Make sure llm_parser.py has run successfully first")
        cursor.close()
        conn.close()
        return
    
    print(f"\n Found {len(json_files)} JSON file(s) to process\n")

    for json_file in json_files:
        json_path = os.path.join(JSON_DIR, json_file)
        pdf_name = os.path.splitext(json_file)[0] + ".pdf"
        print(f" Inserting questions for {pdf_name}")

        # Read and validate JSON file
        with open(json_path, "r", encoding="utf-8-sig") as f:
            content = f.read().strip()

        if not content:
            print(f" Skipping {json_file} (empty file)\n")
            continue

        try:
            questions = json.loads(content)
        except json.JSONDecodeError as e:
            print(f" Skipping {json_file}: Invalid JSON ({e})\n")
            continue

        try:
            # ðŸ›‘ CRITICAL LOGIC CHANGE: Determine the correct file_id to use
            if pipeline_mode_file_id:
                # Use the ID passed from the Flask pipeline
                file_id = pipeline_mode_file_id
                print(f" Using pipeline file_id: {file_id}")
            else:
                # Fallback to the original logic (database lookup by file name)
                file_id = get_file_id(cursor, pdf_name)
                print(f" Using DB lookup file_id: {file_id}")

            # --------------------------------------------------------

            success_count = 0
            for q in questions:
                question_id = insert_question(cursor, q, file_id)
                
                # Build informative log message
                info_parts = []
                
                page_numbers = q.get('page_numbers', [])
                if page_numbers:
                    if len(page_numbers) == 1:
                        info_parts.append(f"page={page_numbers[0]}")
                    else:
                        info_parts.append(f"pages={'-'.join(map(str, page_numbers))}")
                
                if q.get('difficulty_rating_manual'):
                    info_parts.append(f"difficulty={q.get('difficulty_rating_manual')}")
                
                if q.get('question_options'):
                    info_parts.append(f"{len(q.get('question_options'))} options")
                
                if q.get('question_answer'):
                    info_parts.append("has answer")
                
                page_image_paths = q.get('page_image_paths', [])
                if page_image_paths:
                    if len(page_image_paths) == 1:
                        info_parts.append("has page image")
                    else:
                        info_parts.append(f"{len(page_image_paths)} page images")
                
                extra = f" ({', '.join(info_parts)})" if info_parts else ""
                print(f" Inserted id={question_id} for question_no={q.get('question_no')}{extra}")
                success_count += 1

            conn.commit()
            print(f" Inserted {success_count} / {len(questions)} questions for {pdf_name}\n")

        except Exception as e:
            conn.rollback()
            print(f" Failed for {json_file}: {e}\n")

    cursor.close()
    conn.close()
    print(" Done inserting all questions!")


if __name__ == "__main__":
    process_json_files()